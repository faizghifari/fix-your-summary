{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import spacy\n",
    "\n",
    "from datasets import load_dataset\n",
    "from itertools import tee\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset samsum (C:/Users/user/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e)\n",
      "100%|██████████| 3/3 [00:00<00:00, 130.42it/s]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "dataset = load_dataset(\"samsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise(iterable, reverse=False):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    if reverse:\n",
    "        a, b = tee(reversed(iterable))\n",
    "    else:\n",
    "        a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "def extract_speaker_names(data_list):\n",
    "    speaker_names = set()\n",
    "    for data in data_list:\n",
    "        dialog = data[\"dialogue\"]\n",
    "        for line in dialog.split(\"\\n\"):\n",
    "            speaker = line.split(\":\")[0].strip()\n",
    "            if speaker:\n",
    "                speaker_names.add(speaker)\n",
    "    return list(speaker_names)\n",
    "\n",
    "def extract_entities(data_list):\n",
    "    entities = {}\n",
    "    for data in tqdm(data_list):\n",
    "        dialog = data[\"dialogue\"]\n",
    "        turns = dialog.split(\"\\n\")\n",
    "        for turn in turns:\n",
    "            turn.replace(\"\\r\", \"\")\n",
    "            turn_doc = nlp(turn)\n",
    "            dialog_entities = [ent for ent in turn_doc.ents if not any(char.isdigit() for char in ent.text)]\n",
    "            for ent in dialog_entities:\n",
    "                if ent.label_ not in entities.keys():\n",
    "                    entities[ent.label_] = set()\n",
    "                entities[ent.label_].add(ent.text)\n",
    "    \n",
    "    for k in entities.keys():\n",
    "        entities[k] = list(entities[k])\n",
    "    \n",
    "    return entities\n",
    "\n",
    "def extract_digits(num):\n",
    "    num_ = None\n",
    "    if num.text.isdigit():\n",
    "        num_ = int(num.text)\n",
    "    else:\n",
    "        num_= int(''.join(filter(str.isdigit, num.text)))\n",
    "    \n",
    "    return num_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14732/14732 [08:26<00:00, 29.06it/s]\n"
     ]
    }
   ],
   "source": [
    "entities = extract_entities(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_names = extract_speaker_names(dataset[\"train\"])\n",
    "entities[\"PERSON\"] = speaker_names\n",
    "pronouns = [\"he\", \"she\", \"it\", \"they\", \"him\", \"her\", \"them\", \"his\", \"hers\", \"its\", \"theirs\"]\n",
    "modals = [\"shall\", \"should\", \"can\", \"could\", \"will\", \"would\", \"may\", \"must\", \"might\"]\n",
    "verb_form = [\"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\"]\n",
    "modal_groups = {\n",
    "        \"shall\": [\"shall\", \"should\"],\n",
    "        \"will\": [\"will\", \"'ll\", \"would\"],\n",
    "        \"can\": [\"can\", \"could\"],\n",
    "        \"may\": [\"may\", \"might\"],\n",
    "        \"must\": [\"must\"]\n",
    "    }\n",
    "all_modals = list(set(modals + [modal for group in modal_groups.values() for modal in group]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_labels(labels, label_type, start_idx, end_idx, new_token):\n",
    "    new_labels = []\n",
    "    token_length = len(new_token.split())\n",
    "    for i in range(len(labels)):\n",
    "        if i < start_idx:\n",
    "            new_labels.append(labels[i])\n",
    "        elif i == start_idx:\n",
    "            new_labels.append(f\"B-{label_type}\")\n",
    "            for _ in range(1, token_length):\n",
    "                new_labels.append(f\"I-{label_type}\")\n",
    "        elif i > start_idx and i < end_idx:\n",
    "            continue\n",
    "        else:\n",
    "            new_labels.append(labels[i])\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tags = [\"O\", \"B-E\", \"I-E\", \"B-P\", \"I-P\", \"B-V\", \"I-V\", \"B-N\", \"I-N\", \"B-Q\", \"I-Q\"]\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(label_tags)}\n",
    "id2label = {i: label for i, label in enumerate(label_tags)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity & Pronoun Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_entities(summary, labels, alpha=0.5, **kwargs):\n",
    "    dialog = kwargs[\"dialog\"]\n",
    "    dialog_entities = []\n",
    "    turns = dialog.split(\"\\n\")\n",
    "    for turn in turns:\n",
    "        turn.replace(\"\\r\", \"\")\n",
    "        turn_doc = nlp(turn)\n",
    "        dialog_entities.extend([ent for ent in turn_doc.ents if not any(char.isdigit() for char in ent.text)])\n",
    "\n",
    "    summary_doc = nlp(summary)\n",
    "    summary_entities = [ent for ent in summary_doc.ents if not any(char.isdigit() for char in ent.text)]\n",
    "\n",
    "    num_entities_to_replace = round(alpha * len(summary_entities))\n",
    "    summary_entities = random.sample(summary_entities, num_entities_to_replace)\n",
    "    summary_entities.sort(key=lambda ent: ent.start)\n",
    "\n",
    "    if len(summary_entities) == 0:\n",
    "        return summary, labels\n",
    "\n",
    "    for entity in reversed(summary_entities):\n",
    "        candidates = list(set([ent.text for ent in dialog_entities if ent.label_ == entity.label_]))\n",
    "        if len(candidates) > 1:\n",
    "            new_entity = random.choice(candidates)\n",
    "            while new_entity == entity.text.lower():\n",
    "                new_entity = random.choice(candidates)\n",
    "        else:\n",
    "            new_entity = random.choice(entities[entity.label_])\n",
    "            while new_entity == entity.text.lower():\n",
    "                new_entity = random.choice(entities[entity.label_])\n",
    "        \n",
    "        labels = update_labels(labels, \"E\", entity.start, entity.end, new_entity)\n",
    "        summary = summary[:entity.start_char] + new_entity + summary[entity.end_char:]\n",
    "\n",
    "    return summary, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_pronoun(summary, labels, alpha=0.5, **kwargs):\n",
    "    summary_doc = nlp(summary)\n",
    "    summary_pronouns = [token for token in summary_doc if token.pos_ == \"PRON\"]\n",
    "    \n",
    "    num_pronoun_to_replace = round(alpha * len(summary_pronouns))\n",
    "    summary_pronouns = random.sample(summary_pronouns, num_pronoun_to_replace)\n",
    "    \n",
    "    for token in reversed(summary_doc):\n",
    "        if token.pos_ == \"PRON\" and token in summary_pronouns:\n",
    "            pronoun = token\n",
    "            new_pronoun = random.choice(pronouns)\n",
    "            while new_pronoun == pronoun.text.lower():\n",
    "                new_pronoun = random.choice(pronouns)\n",
    "            \n",
    "            labels = update_labels(labels, \"P\", pronoun.i, pronoun.i + 1, new_pronoun)\n",
    "            summary = summary[:pronoun.idx] + new_pronoun + summary[pronoun.idx + len(pronoun):]\n",
    "    \n",
    "    return summary, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verb Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_verb(summary, labels, alpha=0.5, **kwargs):\n",
    "    # Extract verbs from the dialog\n",
    "    dialog = kwargs[\"dialog\"]    \n",
    "    dialog_doc = nlp(dialog)\n",
    "    dialog_verbs = [token.text for token in dialog_doc if token.pos_ == \"VERB\"]\n",
    "    dialog_verbs = list(set(dialog_verbs))\n",
    "\n",
    "    summary_doc = nlp(summary)\n",
    "    summary_verbs = [token for token in summary_doc if token.pos_ == \"VERB\"]\n",
    "\n",
    "    num_verb_to_replace = round(alpha * len(summary_verbs))\n",
    "    summary_verbs = random.sample(summary_verbs, num_verb_to_replace)\n",
    "\n",
    "    # Replace verbs in the summary if only there are more than 1 verb in the dialogue\n",
    "    if len(dialog_verbs) > 1:\n",
    "        for token in reversed(summary_doc):\n",
    "            if token.pos_ == \"VERB\" and token in summary_verbs:\n",
    "                verb = token\n",
    "                new_verb = random.choice(dialog_verbs)\n",
    "                while new_verb == verb.text.lower():\n",
    "                    new_verb = random.choice(dialog_verbs)\n",
    "                \n",
    "                labels = update_labels(labels, \"V\", verb.i, verb.i + 1, new_verb)\n",
    "                summary = summary[:verb.idx] + new_verb + summary[verb.idx + len(verb):]\n",
    "\n",
    "    return summary, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_verb_form(summary, labels, alpha=0.5, **kwargs):\n",
    "    summary_doc = nlp(summary)\n",
    "    summary_verbs = [token for token in summary_doc if token.pos_ == \"VERB\"]\n",
    "\n",
    "    num_verb_to_replace = round(alpha * len(summary_verbs))\n",
    "    summary_verbs = random.sample(summary_verbs, num_verb_to_replace)\n",
    "\n",
    "    for token in reversed(summary_doc):\n",
    "        if token.pos_ == \"VERB\" and token in summary_verbs:\n",
    "            verb = token\n",
    "            \n",
    "            new_form = random.choice(verb_form)\n",
    "            new_verb = token._.inflect(new_form)\n",
    "            if new_verb is None:\n",
    "                continue\n",
    "            while new_verb == verb.text.lower():\n",
    "                new_form = random.choice(verb_form)\n",
    "                new_verb = token._.inflect(new_form)\n",
    "            \n",
    "            labels = update_labels(labels, \"V\", verb.i, verb.i + 1, new_verb)\n",
    "            summary = summary[:verb.idx] + new_verb + summary[verb.idx + len(verb):]\n",
    "    \n",
    "    return summary, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_modal(summary, labels, alpha=0.5, **kwargs):\n",
    "    summary_doc = nlp(summary)\n",
    "    summary_modals = [token for token in summary_doc if token.pos_ == \"MD\" or token.text == \"'ll\"]\n",
    "\n",
    "    num_modal_to_replace = round(alpha * len(summary_modals))\n",
    "    summary_modals = random.sample(summary_modals, num_modal_to_replace)\n",
    "    \n",
    "    for token in reversed(summary_doc):\n",
    "        if token.tag_ == \"MD\" and token in summary_modals:\n",
    "            modal = token\n",
    "            modal_group = None\n",
    "            # Find the group that this modal belongs to\n",
    "            for group, modals in modal_groups.items():\n",
    "                if modal.text.lower() in modals:\n",
    "                    modal_group = group\n",
    "                    break\n",
    "            \n",
    "            new_modal = random.choice([m for m in all_modals if m not in modal_groups.get(modal_group, [])])\n",
    "            while new_modal == modal.text.lower():\n",
    "                new_modal = random.choice(modals)\n",
    "\n",
    "            labels = update_labels(labels, \"V\", modal.i, modal.i + 1, new_modal)\n",
    "            summary = summary[:modal.idx] + new_modal + summary[modal.idx + len(modal):]\n",
    "\n",
    "    return summary, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantity Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_quantity(summary, labels, alpha=0.5, **kwargs):\n",
    "    dialog = kwargs[\"dialog\"]    \n",
    "    dialog_doc = nlp(dialog)\n",
    "    dialog_nums = [token for token in dialog_doc if token.pos_ == \"NUM\"]\n",
    "    date_num = list(set([num.text for num in dialog_nums if num.ent_type_ == \"DATE\"]))\n",
    "    time_num = list(set([num.text for num in dialog_nums if num.ent_type_ == \"TIME\"]))\n",
    "    \n",
    "    summary_doc = nlp(summary)\n",
    "    summary_num = [token for token in summary_doc if token.pos_ == \"NUM\"]\n",
    "\n",
    "    num_num_to_replace = round(alpha * len(summary_num))\n",
    "    summary_num = random.sample(summary_num, num_num_to_replace)\n",
    "\n",
    "    for token in reversed(summary_doc):\n",
    "        if token.pos_ == \"NUM\" and token in summary_num and any(char.isdigit() for char in token.text):\n",
    "            num = token\n",
    "            if num.ent_type_ == \"DATE\":\n",
    "                if len(date_num) > 1:\n",
    "                    new_num = random.choice(date_num)\n",
    "                    while new_num == num.text:\n",
    "                        new_num = random.choice(date_num)\n",
    "                else:\n",
    "                    num_ = extract_digits(num)\n",
    "                    if num_ > 1000:\n",
    "                        new_num = str(random.randint(num_ - 20, num_ + 20))\n",
    "                    else:\n",
    "                        if num_ > 31:\n",
    "                            new_num = str(random.randint(1, 31))\n",
    "                        else:\n",
    "                            new_num = str(random.randint(max(1, num_ - 5), min(31, num_ + 5)))\n",
    "            elif num.ent_type_ == \"TIME\" or \":\" in num.text:\n",
    "                if len(time_num) > 1:\n",
    "                    new_num = random.choice(time_num)\n",
    "                    while new_num == num.text:\n",
    "                        new_num = random.choice(time_num)\n",
    "                else:\n",
    "                    if \":\" in num.text or \".\" in num.text:\n",
    "                        if \":\" in num.text:\n",
    "                            num_ = num.text.split(\":\")\n",
    "                        elif \".\" in num.text:\n",
    "                            num_ = num.text.split(\".\")\n",
    "                        hour = int(num_[0])\n",
    "                        minute = int(num_[1])\n",
    "                        new_num = str(random.randint(max(0, hour - 5), min(23, hour + 5))) + \":\" + str(random.randint(max(0, minute - 10), min(59, minute + 10)))\n",
    "                    else:\n",
    "                        num_ = extract_digits(num)\n",
    "                        if num_ > 23:\n",
    "                            new_num = str(random.randint(0, 23))\n",
    "                        else:\n",
    "                            new_num = str(random.randint(max(0, num_ - 5), min(23, num_ + 5)))\n",
    "            else:\n",
    "                num_ = extract_digits(num)\n",
    "                new_num = str(random.randint(max(1, num_ - 10), num_ + 10))\n",
    "            \n",
    "            labels = update_labels(labels, \"Q\", num.i, num.i + 1, new_num)\n",
    "            summary = summary[:num.idx] + new_num + summary[num.idx + len(num):]\n",
    "    \n",
    "    return summary, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noun Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_noun(summary, labels, alpha=0.5, **kwargs):\n",
    "    # Extract nouns from the dialog\n",
    "    dialog = kwargs[\"dialog\"]\n",
    "    dialog_doc = nlp(dialog)\n",
    "    dialog_nouns = [token.text for token in dialog_doc if token.pos_ == \"NOUN\" and not token.ent_type_]\n",
    "    dialog_nouns = list(set(dialog_nouns))\n",
    "    \n",
    "    summary_doc = nlp(summary)\n",
    "    summary_nouns = [token for token in summary_doc if token.pos_ == \"NOUN\" and not token.ent_type_]\n",
    "\n",
    "    num_noun_to_replace = round(alpha * len(summary_nouns))\n",
    "    summary_nouns = random.sample(summary_nouns, num_noun_to_replace)\n",
    "\n",
    "    # Replace nouns in the summary if only there are more than 1 noun in the dialogue\n",
    "    if len(dialog_nouns) > 1:\n",
    "        for token in reversed(summary_doc):\n",
    "            if token.pos_ == \"NOUN\" and not token.ent_type_ and token in summary_nouns:\n",
    "                noun = token\n",
    "                new_noun = random.choice(dialog_nouns)\n",
    "                while new_noun == noun.text.lower():\n",
    "                    new_noun = random.choice(dialog_nouns)\n",
    "                \n",
    "                labels = update_labels(labels, \"N\", noun.i, noun.i + 1, new_noun)\n",
    "                summary = summary[:noun.idx] + new_noun + summary[noun.idx + len(noun):]\n",
    "\n",
    "    return summary, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AdamW\n",
    "\n",
    "# Load the pre-trained BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased', use_fast=True)\n",
    "\n",
    "# Load the pre-trained BERT model with a token classification head\n",
    "model = AutoModelForTokenClassification.from_pretrained('bert-base-cased', id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14732it [12:14, 20.07it/s]\n",
      "819it [00:41, 19.97it/s]\n",
      "818it [00:40, 20.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "X = 0.5  # percentage of data to distort\n",
    "Y = 0.5  # percentage of distort functions to use\n",
    "distort_funcs = [\n",
    "    replace_entities,\n",
    "    replace_noun,\n",
    "    replace_pronoun,\n",
    "    replace_verb,\n",
    "    replace_verb_form,\n",
    "    replace_modal,\n",
    "    replace_quantity,\n",
    "    replace_noun,\n",
    "]\n",
    "\n",
    "def distort_data(summary, labels, dialogue):\n",
    "    # randomly choose distort functions\n",
    "    num_funcs = len(distort_funcs)\n",
    "    num_to_use = int(Y * num_funcs)\n",
    "    funcs_to_use = random.sample(distort_funcs, num_to_use)\n",
    "\n",
    "    # apply distort functions\n",
    "    for func in funcs_to_use:\n",
    "        summary, labels = func(summary, labels, dialog=dialogue)\n",
    "\n",
    "    return summary, labels\n",
    "\n",
    "def create_data_point(data, distort):\n",
    "    summary_doc = nlp(data[\"summary\"])\n",
    "    summary = \" \".join(token.text for token in summary_doc)\n",
    "    labels = [\"O\"] * len(summary.split())\n",
    "    if distort:\n",
    "        summary, labels = distort_data(summary, labels, data[\"dialogue\"])\n",
    "    summary = summary.split()\n",
    "    \n",
    "    if len(summary) != len(labels):\n",
    "        print([token.text for token in summary_doc])\n",
    "        print(summary)\n",
    "        print(labels)\n",
    "        raise Exception()\n",
    "\n",
    "    return summary, labels\n",
    "\n",
    "# create distorted and non-distorted data\n",
    "new_dataset = DatasetDict()\n",
    "\n",
    "for split in dataset.keys():\n",
    "    ids = []\n",
    "    dialogues = []\n",
    "    ref_summaries = []\n",
    "    distorted_summaries = []\n",
    "    labels = []\n",
    "\n",
    "    total_data = len(dataset[split])\n",
    "    num_to_distort = int(X * total_data)\n",
    "    indices_to_distort = random.sample(range(total_data), num_to_distort)\n",
    "\n",
    "    for i, data in tqdm(enumerate(dataset[split])):\n",
    "        distorted_summary, raw_labels = create_data_point(data, i in indices_to_distort)\n",
    "        dialog_doc = nlp(data[\"dialogue\"])\n",
    "        dialog = [token.text for token in dialog_doc]\n",
    "\n",
    "        ids.append(data[\"id\"])\n",
    "        dialogues.append(dialog)\n",
    "        ref_summaries.append(data[\"summary\"])\n",
    "        distorted_summaries.append(distorted_summary)\n",
    "        labels.append([label2id[label] for label in raw_labels])\n",
    "    new_dataset[split] = Dataset.from_dict({\n",
    "        \"ids\": ids,\n",
    "        \"dialogues\": dialogues,\n",
    "        \"ref_summaries\": ref_summaries,\n",
    "        \"distorted_summaries\": distorted_summaries,\n",
    "        \"labels\": labels,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids, context_len):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for i in range(len(word_ids)):\n",
    "        if i < context_len + 2:\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            if word_ids[i] != current_word:\n",
    "                # Start of a new word!\n",
    "                current_word = word_ids[i]\n",
    "                label = -100 if word_ids[i] is None else labels[word_ids[i]]\n",
    "                new_labels.append(label)\n",
    "            else:\n",
    "                # Special token or same word as prev. token\n",
    "                new_labels.append(-100)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    tokenized_inputs = tokenizer(data['dialogues'], data['distorted_summaries'], is_split_into_words=True, truncation=True, max_length=512)\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(data[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        dialogue = data[\"dialogues\"][i]\n",
    "        context_len = len(tokenizer.tokenize(dialogue, is_split_into_words=True))\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids, context_len))\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = new_dataset.map(\n",
    "    preprocess_data,\n",
    "    batched=True,\n",
    "    remove_columns=new_dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\fix-your-summary\\venv\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/9210 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "  0%|          | 11/9210 [01:52<32:18:18, 12.64s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[751], line 27\u001b[0m\n\u001b[0;32m      4\u001b[0m args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[0;32m      5\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./model/span-predictor/bert-base-cased\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     learning_rate\u001b[39m=\u001b[39m\u001b[39m2e-5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     load_best_model_at_end\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m     19\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     20\u001b[0m     args\u001b[39m=\u001b[39margs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     tokenizer\u001b[39m=\u001b[39mtokenizer,\n\u001b[0;32m     26\u001b[0m )\n\u001b[1;32m---> 27\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[1;32md:\\dev\\fix-your-summary\\venv\\lib\\site-packages\\transformers\\trainer.py:1633\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1630\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1631\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1632\u001b[0m )\n\u001b[1;32m-> 1633\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1634\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1635\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1636\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1637\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1638\u001b[0m )\n",
      "File \u001b[1;32md:\\dev\\fix-your-summary\\venv\\lib\\site-packages\\transformers\\trainer.py:1902\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1900\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1901\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1902\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1904\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1905\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1906\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1907\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1908\u001b[0m ):\n\u001b[0;32m   1909\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1910\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32md:\\dev\\fix-your-summary\\venv\\lib\\site-packages\\transformers\\trainer.py:2663\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2661\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeepspeed\u001b[39m.\u001b[39mbackward(loss)\n\u001b[0;32m   2662\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2663\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m   2665\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach()\n",
      "File \u001b[1;32md:\\dev\\fix-your-summary\\venv\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32md:\\dev\\fix-your-summary\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=f\"./model/span-predictor/bert-base-cased\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=f\"./model/span-predictor/bert-base-cased\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    num_train_epochs=5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
